{"cells":[{"metadata":{"id":"q24VEuL2PbvT"},"cell_type":"markdown","source":"![alt text](https://drive.google.com/uc?export=view&id=1UXScsVx_Wni_JuDdB8LeTnM6jsPfIwkW)\n\nProprietary content. Â© Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."},{"metadata":{"id":"NgR0j5310qqC"},"cell_type":"markdown","source":"# Face Mask Prediction using U-Net\nTask is to predict the mask around the face in a given image."},{"metadata":{"id":"VvWl3ebqzCc1"},"cell_type":"markdown","source":"# Instructions\n- Some part of the code is already done for you\n- You need to execute all the cells\n- You need to add the code where ever you see `\"#### Add your code here ####\"`\n- Marks are mentioned along with the cells"},{"metadata":{"id":"Aa0jyJzw091I"},"cell_type":"markdown","source":"## Dataset\nFaces in images marked with bounding boxes. Have around 409 images with around 1000 faces manually tagged via bounding box.\n- Data file name: images.npy"},{"metadata":{},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt","execution_count":1,"outputs":[]},{"metadata":{"id":"3srplE-FEpKa"},"cell_type":"markdown","source":"### Load the \"images.npy\" file (2 marks)\n- This file contains images with details of bounding boxes"},{"metadata":{"id":"MqFE_tZDf0sM","trusted":true},"cell_type":"code","source":"data = np.load('../input/facemaskimages/images.npy', allow_pickle=True)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"(409, 2)"},"metadata":{}}]},{"metadata":{"id":"_SMP8zliFT7R"},"cell_type":"markdown","source":"### Check one sample from the loaded \"images.npy\" file  (3 marks)\n- Hint: print data[10][1] "},{"metadata":{"trusted":true},"cell_type":"code","source":"data[10][1]","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"[{'label': ['Face'],\n  'notes': '',\n  'points': [{'x': 0.48, 'y': 0.10385756676557864},\n   {'x': 0.7716666666666666, 'y': 0.6795252225519288}],\n  'imageWidth': 600,\n  'imageHeight': 337}]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"    Hence, the 11th data point has label as face, and the top left and top right points are given above along with the image width and size"},{"metadata":{"id":"m94G4p3CE5Cj"},"cell_type":"markdown","source":"### Set image dimensions   (2 marks)\n- Initialize image height, image width with value: 224 "},{"metadata":{"id":"kuZmtOASevDo","trusted":true},"cell_type":"code","source":"# Bringing the image dimensions to a pre-defined value i.e. 224\n\nIMAGE_HEIGHT = 224\nIMAGE_WIDTH = 224","execution_count":5,"outputs":[]},{"metadata":{"id":"wY6FEsCjG47s"},"cell_type":"markdown","source":"### Create features and labels\n- Here feature is the image\n- The label is the mask\n- Images will be stored in \"X\" array\n- Masks will be stored in \"masks\" array"},{"metadata":{"id":"XjCT9EVTgAvr","trusted":true},"cell_type":"code","source":"import cv2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nmasks = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH))\nX = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH, 3))\nfor index in range(data.shape[0]):\n    img = data[index][0]\n    img = cv2.resize(img, dsize=(IMAGE_HEIGHT, IMAGE_WIDTH), interpolation=cv2.INTER_CUBIC)\n    try:\n      img = img[:, :, :3]\n    except:\n      continue\n    X[index] = preprocess_input(np.array(img, dtype=np.float32))\n    for i in data[index][1]:\n        x1 = int(i[\"points\"][0]['x'] * IMAGE_WIDTH)\n        x2 = int(i[\"points\"][1]['x'] * IMAGE_WIDTH)\n        y1 = int(i[\"points\"][0]['y'] * IMAGE_HEIGHT)\n        y2 = int(i[\"points\"][1]['y'] * IMAGE_HEIGHT)\n        masks[index][y1:y2, x1:x2] = 1","execution_count":null,"outputs":[]},{"metadata":{"id":"N3AYbP79bFtJ"},"cell_type":"markdown","source":"### Split the data into training and testing (3 marks)\n- 400 images in training\n- 9 images in testing data"},{"metadata":{"id":"-Uc0NmqXQtPK"},"cell_type":"markdown","source":"Training data"},{"metadata":{"id":"3PIRaEdWIjDa","trusted":true},"cell_type":"code","source":"X_train = X[:399]\ny_train = masks[:399]","execution_count":null,"outputs":[]},{"metadata":{"id":"7ybyn6QnQ4ID"},"cell_type":"markdown","source":"Testing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X[400:408]\ny_test = masks[400:408]","execution_count":null,"outputs":[]},{"metadata":{"id":"R4wgkWq1bk5F"},"cell_type":"markdown","source":"### Print a sample training image, image array and its mask (3 marks)"},{"metadata":{"id":"gfqobMQoRCW-"},"cell_type":"markdown","source":"Print the image and image array"},{"metadata":{"id":"qfRZjQufj0N9","trusted":true},"cell_type":"code","source":"# Image Array\nprint(X_train[6][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image\nplt.imshow(X_train[6])","execution_count":null,"outputs":[]},{"metadata":{"id":"cctmS46hJKnL"},"cell_type":"markdown","source":"Print the mask"},{"metadata":{"id":"983gGKcwlSe8","trusted":true},"cell_type":"code","source":"# Image Mask\nplt.imshow(masks[6])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    From the above mask image, the masks are almost correctly bounding the faces"},{"metadata":{"id":"Z0Qa1UOue9TE"},"cell_type":"markdown","source":"## Create the model (7 marks)\n- Add MobileNet as model with below parameter values\n  - input_shape: IMAGE_HEIGHT, IMAGE_WIDTH, 3\n  - include_top: False\n  - alpha: 1.0\n  - weights: \"imagenet\"\n- Add UNET architecture layers\n  - This is the trickiest part of the project, you need to research and implement it correctly"},{"metadata":{"id":"BTVYOvANrUVx","trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Reshape, UpSampling2D, Concatenate, Conv2D\nfrom tensorflow.keras.models import Model\n\ndef create_model(trainable=True):\n    model = MobileNetV2(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), include_top=False, alpha=1.0, weights=\"imagenet\")\n\n    for layer in model.layers:\n        layer.trainable = trainable\n  \n    s = tf.keras.layers.Lambda(lambda x: x / 224)(model.input)\n\n    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(s)\n    c1 = tf.keras.layers.Dropout(0.1)(c1)\n    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(c1)\n    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n\n    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(p1)\n    c2 = tf.keras.layers.Dropout(0.1)(c2)\n    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(c2)\n    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n\n    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(p2)\n    c3 = tf.keras.layers.Dropout(0.2)(c3)\n    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(c3)\n    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n\n    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(p3)\n    c4 = tf.keras.layers.Dropout(0.2)(c4)\n    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(c4)\n    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n\n    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(p4)\n    c5 = tf.keras.layers.Dropout(0.3)(c5)\n    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(c5)\n\n    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n    u6 = tf.keras.layers.concatenate([u6, c4])\n    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(u6)\n    c6 = tf.keras.layers.Dropout(0.2)(c6)\n    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(c6)\n\n    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n    u7 = tf.keras.layers.concatenate([u7, c3])\n    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(u7)\n    c7 = tf.keras.layers.Dropout(0.2)(c7)\n    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(c7)\n\n    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n    u8 = tf.keras.layers.concatenate([u8, c2])\n    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(u8)\n    c8 = tf.keras.layers.Dropout(0.1)(c8)\n    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(c8)\n\n    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(u9)\n    c9 = tf.keras.layers.Dropout(0.1)(c9)\n    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n                            padding='same')(c9)\n\n    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n\n    model_final = tf.keras.Model(inputs=model.input, outputs=[outputs])\n    return model_final","execution_count":null,"outputs":[]},{"metadata":{"id":"_snZ9o0ZBAiv"},"cell_type":"markdown","source":"### Call the create_model function (2 marks)\n- Give trainable=False as argument, if you want to freeze lower layers for fast training (but low accuracy)"},{"metadata":{"id":"9TfSSP51uPoO","trusted":true},"cell_type":"code","source":"model_to_use = create_model(False)","execution_count":null,"outputs":[]},{"metadata":{"id":"lUr_ZSHkKb5G"},"cell_type":"markdown","source":"### Print model summary (2 marks)"},{"metadata":{"id":"xXCbBt78KfT-","trusted":true},"cell_type":"code","source":"# model_to_use.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel_to_use.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"2spcE4TvfEZw"},"cell_type":"markdown","source":"### Define dice coefficient function (3 marks)\n- Create a function to calculate dice coefficient\n"},{"metadata":{"id":"8H8aViXZuWz1","trusted":true},"cell_type":"code","source":"def dice_coefficient(y_true, y_pred):\n    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n    denominator = tf.reduce_sum(y_true + y_pred)\n\n    return numerator / (denominator + tf.keras.backend.epsilon())","execution_count":null,"outputs":[]},{"metadata":{"id":"Nkp5SDM1fIu2"},"cell_type":"markdown","source":"### Define loss function (3 marks)"},{"metadata":{"id":"FEOVfs19KVLv","trusted":true},"cell_type":"code","source":"def loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) - tf.keras.backend.log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())","execution_count":null,"outputs":[]},{"metadata":{"id":"Thltv_akfOMS"},"cell_type":"markdown","source":"### Compile the model (3 marks)\n- Complie the model using below parameters\n  - loss: use the loss function defined above\n  - optimizers: use Adam optimizer\n  - metrics: use dice_coefficient function defined above"},{"metadata":{"id":"atPb8xm2qkK5","trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\n\noptimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel_to_use.compile(loss=loss, optimizer=optimizer, metrics=[dice_coefficient])","execution_count":null,"outputs":[]},{"metadata":{"id":"VTumZyg0fuVy"},"cell_type":"markdown","source":"### Define callbacks (3 marks)\n- Use ModelCheckpoint\n- Use EarlyStopping\n- Use ReduceLROnPlateau"},{"metadata":{"id":"QNlQHt8DMy7h","trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint(\"model-{val_loss:.2f}.h5\", monitor=\"val_loss\", verbose=1, save_best_only=True, save_weights_only=True)\n\nstop = EarlyStopping(monitor=\"val_loss\", patience=5)\n\nreduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"LxxbwvXEf07e"},"cell_type":"markdown","source":"### Fit the model (3 marks)\n- Fit the model using below parameters\n  - epochs: you can decide\n  - batch_size: 1\n  - callbacks: use the callbacks defined above"},{"metadata":{"id":"guFfKsEmq58j","trusted":true},"cell_type":"code","source":"model_to_use.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=1, batch_size=15, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"5VtnuzlOf4uL"},"cell_type":"markdown","source":"### Get the predicted mask for a test image   (3 marks)"},{"metadata":{"id":"EKeEPrQJNqpq"},"cell_type":"markdown","source":"Show the test image"},{"metadata":{"id":"o-CBCMysrchu","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport random\n\nidx = random.randint(0, len(X_test))\n\nplt.imshow(X_test[idx])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"0HuDvCJHNuwF"},"cell_type":"markdown","source":"Show original mask for test image"},{"metadata":{"id":"fvUuZu2zNxuj","trusted":true},"cell_type":"code","source":"plt.imshow(np.squeeze(masks[idx]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"IJjNguwlN6rI"},"cell_type":"markdown","source":"Predict the mask on the test image"},{"metadata":{"id":"X2dmz90gOcIr","trusted":true},"cell_type":"code","source":"x=np.array(X_test[idx])\nx=np.expand_dims(x, axis=0)\npredict = model_to_use.predict(x, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"fDIetz0HgA4R"},"cell_type":"markdown","source":"### Impose the mask on the test image (3 marks)\n- In imshow use the alpha parameter and set it to greater than 0.5"},{"metadata":{"id":"MTAHGkb5xdzu","trusted":true},"cell_type":"code","source":"plt.imshow(np.squeeze(predict[0]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}